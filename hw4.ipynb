{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "01beebdb",
      "metadata": {
        "id": "01beebdb"
      },
      "source": [
        "# EE 344 — Assignment 4: Fake News Classification\n",
        "\n",
        "In this assignment, you will classify news articles as **fake vs real** using **text features**.\n",
        "Your tasks for this assignment are as follows:\n",
        "\n",
        "1. Learn how to extract text features by vectorizing textual inputs using **CountVectorizer (Bag-of-Words)**.\n",
        "2. Implement **7 classifiers**: Logistic Regression, Perceptron, Linear SVM (LinearSVC), Multinomial Naive Bayes, KNN, Decision Tree, and Random Forest.\n",
        "3. Evaluate **train and test** performance using **accuracy, precision, recall, and F1-score**.\n",
        "4. Provide brief answers to discussion questions about (i) the text feature extraction method you implemented and (ii) the effect of using two different KNN distance choices (**Euclidean vs cosine**).\n",
        "\n",
        "\n",
        "## Submission guidelines\n",
        "- Complete all **[TODO]** blocks in this notebook.\n",
        "- Push the finished notebook to your GitHub repository.\n",
        "- Submit the GitHub link on the Canvas submission page.\n",
        "\n",
        "\n",
        "**Dataset source (for reference only):**  \n",
        "Do **not** download data from the link below. Use the provided `evaluation.csv` file that comes with this assignment.\n",
        "#### https://www.kaggle.com/datasets/aadyasingh55/fake-news-classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0944b7",
      "metadata": {
        "id": "df0944b7"
      },
      "source": [
        "## Setup\n",
        "Run the next cell to import libraries and define helper functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "125eae54",
      "metadata": {
        "id": "125eae54"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    \"\"\"Return (accuracy, precision, recall, f1).\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Use 'binary' for binary classification, otherwise fallback to macro.\n",
        "    avg = \"binary\" if len(np.unique(y_true)) == 2 else \"macro\"\n",
        "\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=avg, zero_division=0\n",
        "    )\n",
        "    return acc, prec, rec, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83ee37a",
      "metadata": {
        "id": "c83ee37a"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Put the dataset file in the same folder as this notebook (recommended), or provide an absolute path.\n",
        "\n",
        "This dataset uses **semicolon-separated** fields and can contain extra semicolons inside the text.\n",
        "So we use a custom loader that safely reconstructs the text column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ce5700b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce5700b1",
        "outputId": "48c00802-6f73-46d2-b614-8315b9a45501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: (7815, 4)\n",
            "Label distribution:\n",
            " label\n",
            "1    4185\n",
            "0    3630\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# === Data path ===\n",
        "# If your file has a different name/path, update it here.\n",
        "DATA_PATH = \"evaluation.csv\"   # <-- change if needed\n",
        "\n",
        "def load_semicolon_dataset(path):\n",
        "    \"\"\"\n",
        "    Handles lines like:\n",
        "    ;title;text;label\n",
        "    0;some title;some text that may contain ; ; ; ;0\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "        _ = f.readline()  # header\n",
        "        for line in f:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split(\";\")\n",
        "            if len(parts) < 4:\n",
        "                continue\n",
        "\n",
        "            idx = parts[0]\n",
        "            title = parts[1]\n",
        "            label = parts[-1]\n",
        "            text = \";\".join(parts[2:-1])  # re-join any extra ';' inside text\n",
        "            rows.append((idx, title, text, label))\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"id\", \"title\", \"text\", \"label\"])\n",
        "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"label\"]).reset_index(drop=True)\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return df\n",
        "\n",
        "df = load_semicolon_dataset(DATA_PATH)\n",
        "print(\"Dataset:\", df.shape)\n",
        "print(\"Label distribution:\\n\", df[\"label\"].value_counts())\n",
        "\n",
        "# Combine title + text into one string per document\n",
        "docs = (df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")).astype(str).tolist()\n",
        "y = df[\"label\"].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6df6766",
      "metadata": {
        "id": "b6df6766"
      },
      "source": [
        "## Train/test split\n",
        "\n",
        "We keep a standard **80/20** split with stratification (preserves label ratio).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d3ca0b1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ca0b1a",
        "outputId": "a9fad0e6-d594-4d3e-8913-09d54b46d153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train docs: 6252 Test docs: 1563\n"
          ]
        }
      ],
      "source": [
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    docs, y,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train docs:\", len(X_train_text), \"Test docs:\", len(X_test_text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39543025",
      "metadata": {
        "id": "39543025"
      },
      "source": [
        "## Case Study: Bag-of-Words Features (CountVectorizer)\n",
        "\n",
        "We need to convert text into numeric features before we can train ML models.\n",
        "\n",
        "**CountVectorizer** builds a vocabulary from the **training set** and represents each document as a vector of **counts** (one entry per vocabulary term).\n",
        "\n",
        "We will use:\n",
        "$$\n",
        "\\texttt{CountVectorizer(}\n",
        "\\texttt{lowercase=True, stop_words=\"english\", ngram_range=(1,2),}\n",
        "$$\n",
        "$$\n",
        "\\texttt{ min_df=2, max_df=0.9, max_features=10000)}\n",
        "$$\n",
        "\n",
        "**What each setting means (briefly):**\n",
        "- `lowercase=True`: convert text to lowercase before building features.\n",
        "- `stop_words=\"english\"`: remove a predefined list of common English words.\n",
        "- `ngram_range=(1,2)`: allow 1-word features and 2-word features (bigrams).\n",
        "- `min_df=2`: keep a term only if it appears in at least 2 training documents.\n",
        "- `max_df=0.9`: drop a term if it appears in more than 90% of training documents.\n",
        "- `max_features=10000`: cap the vocabulary size at 10,000 terms (after filtering).\n",
        "\n",
        "### Tiny example (just to see what it does)\n",
        "\n",
        "We will build features from 3 short documents and look at the counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "aaee0c65",
      "metadata": {
        "id": "aaee0c65"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer docs (read this once before TODO 1):\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b5a2cb96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a2cb96",
        "outputId": "cde73aa0-b478-4429-830f-55e84cc16d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toy vocab: ['fake', 'fake news', 'news', 'news spreads', 'spreads']\n",
            "Toy counts (rows = docs):\n",
            " [[1 1 1 1 1]\n",
            " [1 1 1 1 1]\n",
            " [0 0 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "toy_docs = [\n",
        "    \"The FAKE news spreads fast\",\n",
        "    \"Fake news spreads\",\n",
        "    \"Real news spreads\",\n",
        "]\n",
        "\n",
        "toy_vec = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    stop_words=\"english\",\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2\n",
        ")\n",
        "\n",
        "toy_X = toy_vec.fit_transform(toy_docs)\n",
        "\n",
        "print(\"Toy vocab:\", list(toy_vec.get_feature_names_out()))\n",
        "print(\"Toy counts (rows = docs):\\n\", toy_X.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081e3f66",
      "metadata": {
        "id": "081e3f66"
      },
      "source": [
        "## Build Bag-of-Words features\n",
        "\n",
        "Goal:\n",
        "1. Create the `CountVectorizer` using the exact settings below.\n",
        "2. Fit on the training text only.\n",
        "3. Transform both train and test text into sparse Bag-of-Words features.\n",
        "\n",
        "Notes:\n",
        "- `fit_transform` on train, then `transform` on test.\n",
        "- The output is a **sparse matrix** (CSR). That is normal for text features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a6a1edcc",
      "metadata": {
        "id": "a6a1edcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BoW shapes: (6252, 10000) (1563, 10000)\n"
          ]
        }
      ],
      "source": [
        "# --- Bag-of-Words settings ---\n",
        "MAX_FEATURES = 10000\n",
        "NGRAM_RANGE = (1, 2)\n",
        "\n",
        "## [ TODO 1 ]\n",
        "# 1) Create `vectorizer` using CountVectorizer with:\n",
        "#    lowercase=True\n",
        "#    stop_words=\"english\"\n",
        "#    ngram_range=NGRAM_RANGE\n",
        "#    min_df=2\n",
        "#    max_df=0.9\n",
        "#    max_features=MAX_FEATURES\n",
        "#\n",
        "# 2) Fit the vectorizer on the training text, then use it to transform:\n",
        "#    - the training text into BoW features\n",
        "#    - the test text into BoW features\n",
        "#\n",
        "# (Reminder: fit on train only; do NOT fit on test.)\n",
        "#\n",
        "# Print the BoW shapes.\n",
        "vectorizer = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    stop_words='english',\n",
        "    ngram_range=NGRAM_RANGE,\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        "    max_features=MAX_FEATURES\n",
        ")\n",
        "\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "print(\"BoW shapes:\", X_train_bow.shape, X_test_bow.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5127e270",
      "metadata": {
        "id": "5127e270"
      },
      "source": [
        "## Models\n",
        "\n",
        "Create **7 classifiers** using the exact hyperparameters below.\n",
        "\n",
        "**Important:** For KNN in this notebook, start with **Euclidean distance**.\n",
        "\n",
        "Models to implement:\n",
        "- Logistic Regression: `solver=\"saga\"`, `max_iter=2000`, `n_jobs=-1`, `random_state=42`\n",
        "- Perceptron: `max_iter=1000`, `tol=1e-3`, `random_state=42`\n",
        "- SVM (LinearSVC): `random_state=42`\n",
        "- Naive Bayes (MultinomialNB): `alpha=1.0`\n",
        "- KNN (Euclidean): `n_neighbors=7`, `metric=\"euclidean\"`, `n_jobs=-1`\n",
        "- Decision Tree: `max_depth=40`, `random_state=42`\n",
        "- Random Forest: `n_estimators=300`, `random_state=42`, `n_jobs=-1`\n",
        "\n",
        "Put them in a dictionary named `models`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "78772066",
      "metadata": {
        "id": "78772066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Logistic Regression': LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42, solver='saga'),\n",
              " 'Perceptron': Perceptron(random_state=42),\n",
              " 'SVM': LinearSVC(random_state=42),\n",
              " 'Naive Bayes': MultinomialNB(),\n",
              " 'KNN (Euclidean)': KNeighborsClassifier(metric='euclidean', n_jobs=-1, n_neighbors=7),\n",
              " 'KNN (Cosine)': KNeighborsClassifier(algorithm='brute', metric='cosine', n_jobs=-1,\n",
              "                      n_neighbors=7),\n",
              " 'Decision Tree': DecisionTreeClassifier(max_depth=40, random_state=42),\n",
              " 'Random Forest': RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## [ TODO 2 ]\n",
        "# Build the `models` dictionary using the exact parameters above.\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(solver='saga', max_iter=2000, n_jobs=-1, random_state=42),\n",
        "    'Perceptron': Perceptron(max_iter=1000, tol=1e-3, random_state=42),\n",
        "    'SVM': LinearSVC(random_state=42),\n",
        "    'Naive Bayes': MultinomialNB(alpha=1.0),\n",
        "    'KNN (Euclidean)': KNeighborsClassifier(n_neighbors=7, metric='euclidean', n_jobs=-1),\n",
        "    'KNN (Cosine)': KNeighborsClassifier(n_neighbors=7, metric='cosine', algorithm='brute', n_jobs=-1),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=40, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1adacab",
      "metadata": {
        "id": "c1adacab"
      },
      "source": [
        "## Train + evaluate\n",
        "\n",
        "We will evaluate each model on:\n",
        "- **Training set**\n",
        "- **Test set**\n",
        "\n",
        "Metrics:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1\n",
        "\n",
        "We will print a table sorted by **Test F1**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "10fdf1af",
      "metadata": {
        "id": "10fdf1af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tdokkad/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Results (sorted by Test F1) ===\n",
            "              Model Train Acc Train Prec Train Rec Train F1 Test Acc Test Prec Test Rec Test F1\n",
            "      Random Forest    1.0000     1.0000    1.0000   1.0000   0.9949    0.9976   0.9928  0.9952\n",
            "      Decision Tree    1.0000     1.0000    1.0000   1.0000   0.9904    0.9940   0.9881  0.9910\n",
            "Logistic Regression    0.9989     0.9997    0.9982   0.9990   0.9872    0.9869   0.9892  0.9881\n",
            "                SVM    1.0000     1.0000    1.0000   1.0000   0.9853    0.9857   0.9869  0.9863\n",
            "         Perceptron    1.0000     1.0000    1.0000   1.0000   0.9808    0.9821   0.9821  0.9821\n",
            "        Naive Bayes    0.9624     0.9684    0.9612   0.9648   0.9610    0.9630   0.9642  0.9636\n",
            "       KNN (Cosine)    0.9128     0.8717    0.9818   0.9234   0.8791    0.8299   0.9737  0.8961\n",
            "    KNN (Euclidean)    0.7844     0.8906    0.6810   0.7718   0.7364    0.8571   0.6093  0.7123\n"
          ]
        }
      ],
      "source": [
        "## [ TODO 3 ]\n",
        "# Write a loop that:\n",
        "# 1) fits each model on X_train_bow, y_train\n",
        "# 2) predicts on train and test\n",
        "# 3) computes (acc, prec, rec, f1) using metrics(...)\n",
        "# 4) stores results in a list\n",
        "# 5) prints a DataFrame sorted by Test F1 (descending)\n",
        "#\n",
        "# Use the exact column names below.\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_bow, y_train)\n",
        "\n",
        "    y_pred_train = model.predict(X_train_bow)\n",
        "    y_pred_test = model.predict(X_test_bow)\n",
        "\n",
        "    results.append([\n",
        "        name,\n",
        "        *metrics(y_train, y_pred_train),\n",
        "        *metrics(y_test, y_pred_test)\n",
        "    ])\n",
        "\n",
        "\n",
        "cols = [\n",
        "    \"Model\",\n",
        "    \"Train Acc\", \"Train Prec\", \"Train Rec\", \"Train F1\",\n",
        "    \"Test Acc\", \"Test Prec\", \"Test Rec\", \"Test F1\",\n",
        "]\n",
        "\n",
        "out = pd.DataFrame(results, columns=cols).sort_values(\"Test F1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 80)\n",
        "print(\"\\n=== Results (sorted by Test F1) ===\")\n",
        "print(out.to_string(index=False, formatters={\n",
        "    \"Train Acc\": \"{:.4f}\".format,\n",
        "    \"Train Prec\": \"{:.4f}\".format,\n",
        "    \"Train Rec\": \"{:.4f}\".format,\n",
        "    \"Train F1\": \"{:.4f}\".format,\n",
        "    \"Test Acc\": \"{:.4f}\".format,\n",
        "    \"Test Prec\": \"{:.4f}\".format,\n",
        "    \"Test Rec\": \"{:.4f}\".format,\n",
        "    \"Test F1\": \"{:.4f}\".format,\n",
        "}))\n",
        "\n",
        "# raise NotImplementedError(\"Complete TODO 3 above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e27447",
      "metadata": {
        "id": "51e27447"
      },
      "source": [
        "## Cosine distance for KNN\n",
        "\n",
        "With Bag-of-Words, each document becomes a long vector of word counts (mostly zeros).  \n",
        "To compare two documents, we need a way to measure how “close” two vectors are.\n",
        "\n",
        "Two common choices:\n",
        "\n",
        "- **Euclidean distance**: straight-line distance between two vectors.\n",
        "- **Cosine distance**: based on the angle between two vectors (uses cosine similarity under the hood).\n",
        "\n",
        "In scikit-learn, KNN uses a **distance**. Cosine distance is:\n",
        "$$\n",
        "d_{\\text{cosine}}(x, z) \\;=\\; 1 - \\cos(x, z)\n",
        "\\;=\\; 1 - \\frac{x^\\top z}{\\|x\\|_2 \\,\\|z\\|_2}\n",
        "$$\n",
        "\n",
        "(where $\\cos(x,z)$ is cosine similarity).\n",
        "\n",
        "### Tiny numeric example (no text, just vectors)\n",
        "\n",
        "Let:\n",
        "- $x = [1, 1]$\n",
        "- $z_1 = [2, 2]$  (same direction as $x$, just “bigger”)\n",
        "- $z_2 = [2, 0]$  (different direction)\n",
        "\n",
        "**Euclidean distances**\n",
        "$$\n",
        "\\|x - z_1\\|_2 = \\sqrt{(1-2)^2 + (1-2)^2} = \\sqrt{2}\n",
        "$$\n",
        "$$\n",
        "\\|x - z_2\\|_2 = \\sqrt{(1-2)^2 + (1-0)^2} = \\sqrt{2}\n",
        "$$\n",
        "So Euclidean says $z_1$ and $z_2$ are equally far from $x$ here.\n",
        "\n",
        "**Cosine distances**\n",
        "$$\n",
        "\\cos(x, z_1) = \\frac{1\\cdot 2 + 1\\cdot 2}{\\sqrt{2}\\cdot \\sqrt{8}} = 1\n",
        "\\Rightarrow d_{\\text{cosine}}(x, z_1)=0\n",
        "$$\n",
        "$$\n",
        "\\cos(x, z_2) = \\frac{1\\cdot 2 + 1\\cdot 0}{\\sqrt{2}\\cdot 2} \\approx 0.707\n",
        "\\Rightarrow d_{\\text{cosine}}(x, z_2)\\approx 0.293\n",
        "$$\n",
        "So cosine says $z_1$ is closer to $x$ than $z_2$.\n",
        "\n",
        "### What you will do\n",
        "\n",
        "Keep everything the same, but change your KNN metric from `\"euclidean\"` to `\"cosine\"`, then re-run your evaluation and compare results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "04779264",
      "metadata": {
        "id": "04779264"
      },
      "outputs": [],
      "source": [
        "# Tip: For cosine distance, brute-force search is commonly used.\n",
        "# Example (do not run until TODO 2/3 are done):\n",
        "#\n",
        "# knn_cos = KNeighborsClassifier(\n",
        "#     n_neighbors=7,\n",
        "#     metric=\"cosine\",\n",
        "#     algorithm=\"brute\",\n",
        "#     n_jobs=-1\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace5e4ac",
      "metadata": {
        "id": "ace5e4ac"
      },
      "source": [
        "## Discussion questions (answer in your own words)\n",
        "\n",
        "Write short answers below (2–5 sentences each is enough).\n",
        "\n",
        "### Question A\n",
        "In your own words, what is the added value of allowing 2-word sequences (bigrams) in `ngram_range`?\n",
        "\n",
        "### Question B\n",
        "In your own words, why might someone choose to set both `min_df` and `max_df` when building the vocabulary?\n",
        "\n",
        "### Question C\n",
        "\n",
        "After you run KNN with **Euclidean** and then with **Cosine** distance:\n",
        "\n",
        "- Do you observe any difference in results?\n",
        "- If yes, why do you think the difference happens (your intuition)?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d04ee569",
      "metadata": {
        "id": "d04ee569"
      },
      "source": [
        "**Your answers:**\n",
        "\n",
        "- **A:**  \n",
        "  This allows the model to recognize common phrases (like 'fake news' in the toy example) that are common across the texts analyzed. This is particularly helpful for phrases that have an idiomatic meaning aside from that of the component words.\n",
        "\n",
        "- **B:**  \n",
        "  These parameters do different things; min_df is for removing rare words that occur too infrequently to make a good generalization about what their impact is while max_df is for removing common words (especially lexically weak ones like 'the', 'and', 'is', &c). Either due to sampling error/lack of info or excessive prevalance, both categories fail to be useful diagnostics. Pruning them helps save compute and/or make space for more helpful predictors.\n",
        "\n",
        "- **C:**  \n",
        "  The KNN model using cosine distance performs notably better than the Euclidean difference. It makes sense that cosine distance would work well here because cosine distance, having a hard maximum, can be 'maxed out' easily even in a sparse feature set, and the angle of BoW vectors (what words are featured) is probably a lot more relevant than their magnitudes (how many are featured). At the same time, the BoW features contain no negative values, so that values can approach maximum distance if they have differences in many dimensions but can't hit it directly. I am not entirely sure why the Euclidean distance performs so badly here, however.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
