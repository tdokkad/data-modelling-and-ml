{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d1eafd8",
      "metadata": {
        "id": "8d1eafd8"
      },
      "source": [
        "# EE 344 — Assignment 3: Walmart Weekly Sales Regression\n",
        "\n",
        "In this assignment, you will predict **Weekly_Sales** using tabular store/economic features.\n",
        "\n",
        "To keep things focused, you will do **only one preprocessing mode**:\n",
        "\n",
        "- **scale_all_after_ohe**: one-hot encode categorical features, then standardize *all* resulting features.\n",
        "\n",
        "Then you will train and evaluate **four models** using **fixed hyperparameters** (no grid search):\n",
        "- Elastic Net\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Decision Tree (DT)\n",
        "- Random Forest (RF)\n",
        "\n",
        "---\n",
        "\n",
        "## Submission guidelines\n",
        "- Complete all **[TODO]** blocks in this notebook.\n",
        "- Push the finished notebook to your **GitHub repository**.\n",
        "- Submit the **GitHub link** on the Canvas submission page.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973edfa2",
      "metadata": {
        "id": "973edfa2"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the next cell to import libraries and define helper functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e716318d",
      "metadata": {
        "id": "e716318d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import ElasticNet, Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def evaluate_regression(model, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Fit on train, evaluate on test.\"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    return {\n",
        "        \"MAE\": mean_absolute_error(y_test, pred),\n",
        "        \"RMSE\": rmse(y_test, pred),\n",
        "        \"R2\": r2_score(y_test, pred),\n",
        "    }\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39118f42",
      "metadata": {
        "id": "39118f42"
      },
      "source": [
        "## Load data\n",
        "\n",
        "- Put the dataset CSV in the **same folder** as this notebook (recommended), or provide an absolute path.\n",
        "- We drop the **Date** column (if present).\n",
        "- We treat **Store** and **Holiday_Flag** as categorical.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0aa304d3",
      "metadata": {
        "id": "0aa304d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1643690.90</td>\n",
              "      <td>0</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1641957.44</td>\n",
              "      <td>1</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1611968.17</td>\n",
              "      <td>0</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1409727.59</td>\n",
              "      <td>0</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1554806.68</td>\n",
              "      <td>0</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price         CPI  \\\n",
              "0      1    1643690.90             0        42.31       2.572  211.096358   \n",
              "1      1    1641957.44             1        38.51       2.548  211.242170   \n",
              "2      1    1611968.17             0        39.93       2.514  211.289143   \n",
              "3      1    1409727.59             0        46.63       2.561  211.319643   \n",
              "4      1    1554806.68             0        46.50       2.625  211.350143   \n",
              "\n",
              "   Unemployment  \n",
              "0         8.106  \n",
              "1         8.106  \n",
              "2         8.106  \n",
              "3         8.106  \n",
              "4         8.106  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (6435, 7)\n"
          ]
        }
      ],
      "source": [
        "# === Data path ===\n",
        "# If your CSV file has a different name/path, update it here.\n",
        "DATA_PATH = \"Walmart_Store_sales.csv\"\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Drop Date (if present)\n",
        "if \"Date\" in df.columns:\n",
        "    df = df.drop(columns=[\"Date\"])\n",
        "\n",
        "# Target and features\n",
        "y = df[\"Weekly_Sales\"]\n",
        "X = df.drop(columns=[\"Weekly_Sales\"])\n",
        "\n",
        "# Treat these as categorical (even if stored as ints)\n",
        "for col in [\"Store\", \"Holiday_Flag\"]:\n",
        "    if col in X.columns:\n",
        "        X[col] = X[col].astype(str)\n",
        "\n",
        "display(df.head())\n",
        "print(\"Shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b8327e",
      "metadata": {
        "id": "20b8327e"
      },
      "source": [
        "## Train/test split\n",
        "\n",
        "We keep a standard **80/20 random split**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "44a71e47",
      "metadata": {
        "id": "44a71e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (5148, 6) Test: (1287, 6)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f1da3e",
      "metadata": {
        "id": "16f1da3e"
      },
      "source": [
        "## Preprocessing: scale_all_after_ohe\n",
        "\n",
        "Goal:\n",
        "1) One-hot encode categorical columns (so everything becomes numeric)\n",
        "2) Standardize **all** resulting features\n",
        "\n",
        "You will build a preprocessing pipeline that you can reuse for all four models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a8dd9976",
      "metadata": {
        "id": "a8dd9976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical columns: ['Store', 'Holiday_Flag']\n",
            "Numeric columns: ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n"
          ]
        }
      ],
      "source": [
        "# --- Identify categorical and numeric columns ---\n",
        "# We will treat Store and Holiday_Flag as categorical.\n",
        "# All other columns are numeric (for this dataset).\n",
        "\n",
        "## [ TODO ]\n",
        "# 1) Create a list `cat_cols` that includes the categorical columns present in X\n",
        "# 2) Create a list `num_cols` that includes all remaining columns in X (numeric)\n",
        "#    Hint: You can do this programmatically using X.columns\n",
        "cat_cols = ['Store', 'Holiday_Flag']\n",
        "num_cols = [col for col in list(X.columns) if col not in cat_cols]\n",
        "\n",
        "print(\"Categorical columns:\", cat_cols)\n",
        "print(\"Numeric columns:\", num_cols)\n",
        "\n",
        "# --- Build scale_all_after_ohe preprocessing pipeline ---\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "\n",
        "## [ TODO ]\n",
        "# Create a ColumnTransformer that:\n",
        "# - applies One-hot encoding (OHE) to cat_cols\n",
        "# - passes through num_cols unchanged\n",
        "# Then apply StandardScaler(with_mean=False) to scale all features.\n",
        "#\n",
        "# Name the final pipeline variable: `prep_A`\n",
        "#\n",
        "# Hint: ColumnTransformer(..., remainder=\"drop\")\n",
        "# Hint: StandardScaler(with_mean=False) is sparse-friendly.\n",
        "\n",
        "\n",
        "ohe = ColumnTransformer([\n",
        "        (\"One-hot encoding\", ohe, cat_cols)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "prep_A = Pipeline([\n",
        "    (\"One-hot encoding\", ohe),\n",
        "    (\"Scaling\", StandardScaler(with_mean=False))\n",
        "])\n",
        "\n",
        "PREP_MODES = {\n",
        "    \"scale_all_after_ohe\": prep_A\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d844d2cc",
      "metadata": {
        "id": "d844d2cc"
      },
      "source": [
        "## Implementation of Regression Models\n",
        "\n",
        "Create 4 pipelines, each with:\n",
        "- `(\"prep\", prep_A)`\n",
        "- `(\"model\", <your model with fixed params>)`\n",
        "\n",
        "**Use the exact parameters below:**\n",
        "- RandomForestRegressor: `n_estimators=200`, `max_depth=None`, `max_features=\"sqrt\"`, `min_samples_leaf=1`\n",
        "- KNeighborsRegressor: `n_neighbors=15`, `weights=\"distance\"`\n",
        "- ElasticNet: `alpha=0.001`, `l1_ratio=0.9`\n",
        "- DecisionTreeRegressor: `max_depth=None`, `min_samples_leaf=10`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9d941826",
      "metadata": {
        "id": "9d941826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'RandomForest': Pipeline(steps=[('prep',\n",
              "                  Pipeline(steps=[('One-hot encoding',\n",
              "                                   ColumnTransformer(remainder='passthrough',\n",
              "                                                     transformers=[('One-hot '\n",
              "                                                                    'encoding',\n",
              "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                    ['Store',\n",
              "                                                                     'Holiday_Flag'])])),\n",
              "                                  ('Scaling',\n",
              "                                   StandardScaler(with_mean=False))])),\n",
              "                 ('model',\n",
              "                  RandomForestRegressor(max_features='sqrt', n_estimators=200))]),\n",
              " 'KNN': Pipeline(steps=[('prep',\n",
              "                  Pipeline(steps=[('One-hot encoding',\n",
              "                                   ColumnTransformer(remainder='passthrough',\n",
              "                                                     transformers=[('One-hot '\n",
              "                                                                    'encoding',\n",
              "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                    ['Store',\n",
              "                                                                     'Holiday_Flag'])])),\n",
              "                                  ('Scaling',\n",
              "                                   StandardScaler(with_mean=False))])),\n",
              "                 ('model',\n",
              "                  KNeighborsRegressor(n_neighbors=15, weights='distance'))]),\n",
              " 'ElasticNet': Pipeline(steps=[('prep',\n",
              "                  Pipeline(steps=[('One-hot encoding',\n",
              "                                   ColumnTransformer(remainder='passthrough',\n",
              "                                                     transformers=[('One-hot '\n",
              "                                                                    'encoding',\n",
              "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                    ['Store',\n",
              "                                                                     'Holiday_Flag'])])),\n",
              "                                  ('Scaling',\n",
              "                                   StandardScaler(with_mean=False))])),\n",
              "                 ('model', ElasticNet(alpha=0.001, l1_ratio=0.9))]),\n",
              " 'DecisionTree': Pipeline(steps=[('prep',\n",
              "                  Pipeline(steps=[('One-hot encoding',\n",
              "                                   ColumnTransformer(remainder='passthrough',\n",
              "                                                     transformers=[('One-hot '\n",
              "                                                                    'encoding',\n",
              "                                                                    OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                    ['Store',\n",
              "                                                                     'Holiday_Flag'])])),\n",
              "                                  ('Scaling',\n",
              "                                   StandardScaler(with_mean=False))])),\n",
              "                 ('model', DecisionTreeRegressor(min_samples_leaf=10))])}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## [ TODO ]\n",
        "# Build the 4 pipelines below.\n",
        "#\n",
        "# Notes:\n",
        "# - For ElasticNet, it can help to raise max_iter to avoid convergence warnings.\n",
        "# - For DT/RF, set random_state=RANDOM_STATE for reproducibility.\n",
        "\n",
        "rf_pipe = Pipeline([\n",
        "    ('prep', prep_A),\n",
        "    ('model', RandomForestRegressor(n_estimators=200, \n",
        "                                    max_depth=None, \n",
        "                                    max_features=\"sqrt\", \n",
        "                                    min_samples_leaf=1))\n",
        "])\n",
        "knn_pipe = Pipeline([\n",
        "    ('prep', prep_A),\n",
        "    ('model', KNeighborsRegressor(n_neighbors=15, \n",
        "                                  weights=\"distance\"))\n",
        "])\n",
        "enet_pipe = Pipeline([\n",
        "    ('prep', prep_A),\n",
        "    ('model', ElasticNet(alpha=0.001, \n",
        "                         l1_ratio=0.9))\n",
        "])\n",
        "dt_pipe = Pipeline([\n",
        "    ('prep', prep_A),\n",
        "    ('model', DecisionTreeRegressor(max_depth=None, \n",
        "                                    min_samples_leaf=10))\n",
        "])\n",
        "\n",
        "MODELS = {\n",
        "    \"RandomForest\": rf_pipe,\n",
        "    \"KNN\": knn_pipe,\n",
        "    \"ElasticNet\": enet_pipe,\n",
        "    \"DecisionTree\": dt_pipe,\n",
        "}\n",
        "\n",
        "MODELS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9b50651",
      "metadata": {
        "id": "e9b50651"
      },
      "source": [
        "## Evaluation (CV RMSE + test metrics)\n",
        "\n",
        "Following code block computes:\n",
        "- **5-fold CV RMSE** on the *training set* (for a fair comparison)\n",
        "- **test MAE / RMSE / R²** after fitting on the full training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "51dd5ac5",
      "metadata": {
        "id": "51dd5ac5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52226914479858.77, tolerance: 131770976217.2606\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51313024116001.375, tolerance: 131323286376.3119\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54098220144048.46, tolerance: 129981253904.32805\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51973583527319.15, tolerance: 130806128744.70816\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52445238363041.89, tolerance: 129936350603.35078\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65665778462271.55, tolerance: 163457864416.10596\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Preprocess</th>\n",
              "      <th>Model</th>\n",
              "      <th>Best CV RMSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>scale_all_after_ohe</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>143101.581276</td>\n",
              "      <td>72018.492191</td>\n",
              "      <td>138057.385033</td>\n",
              "      <td>0.940836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>scale_all_after_ohe</td>\n",
              "      <td>KNN</td>\n",
              "      <td>152200.243436</td>\n",
              "      <td>77729.980038</td>\n",
              "      <td>145549.240578</td>\n",
              "      <td>0.934241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scale_all_after_ohe</td>\n",
              "      <td>ElasticNet</td>\n",
              "      <td>161200.729347</td>\n",
              "      <td>90994.710410</td>\n",
              "      <td>159668.487198</td>\n",
              "      <td>0.920864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>scale_all_after_ohe</td>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>160706.062034</td>\n",
              "      <td>89188.546560</td>\n",
              "      <td>164075.787304</td>\n",
              "      <td>0.916435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Preprocess         Model   Best CV RMSE           MAE  \\\n",
              "0  scale_all_after_ohe  RandomForest  143101.581276  72018.492191   \n",
              "1  scale_all_after_ohe           KNN  152200.243436  77729.980038   \n",
              "2  scale_all_after_ohe    ElasticNet  161200.729347  90994.710410   \n",
              "3  scale_all_after_ohe  DecisionTree  160706.062034  89188.546560   \n",
              "\n",
              "            RMSE        R2  \n",
              "0  138057.385033  0.940836  \n",
              "1  145549.240578  0.934241  \n",
              "2  159668.487198  0.920864  \n",
              "3  164075.787304  0.916435  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5-fold CV (shuffle for reproducibility)\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "rows = []\n",
        "\n",
        "for name, pipe in MODELS.items():\n",
        "    # --- CV RMSE ---\n",
        "    # cross_val_score returns NEGATIVE values when using neg_root_mean_squared_error.\n",
        "    cv_scores = cross_val_score(\n",
        "        pipe,\n",
        "        X_train, y_train,\n",
        "        scoring=\"neg_root_mean_squared_error\",\n",
        "        cv=cv,\n",
        "        n_jobs=1\n",
        "    )\n",
        "    cv_rmse = -cv_scores.mean()\n",
        "\n",
        "    # --- Test metrics ---\n",
        "    metrics = evaluate_regression(pipe, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    rows.append({\n",
        "        \"Preprocess\": \"scale_all_after_ohe\",\n",
        "        \"Model\": name,\n",
        "        \"Best CV RMSE\": cv_rmse,\n",
        "        \"MAE\": metrics[\"MAE\"],\n",
        "        \"RMSE\": metrics[\"RMSE\"],\n",
        "        \"R2\": metrics[\"R2\"],\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows).sort_values(\"RMSE\").reset_index(drop=True)\n",
        "display(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iydOqp-yaHfw",
      "metadata": {
        "id": "iydOqp-yaHfw"
      },
      "source": [
        "## Model Stacking (Decision Tree + Elastic Net)\n",
        "\n",
        "A single model might miss patterns that another model captures well.\n",
        "- **Decision Tree** can learn nonlinear splits and feature interactions.\n",
        "- **Elastic Net** is a strong regularized linear model.\n",
        "\n",
        "**Stacking** trains multiple base models, then trains a final model (a *meta-learner*) on their predictions.\n",
        "Here we stack:\n",
        "- base models: **Decision Tree + Elastic Net**\n",
        "- meta-learner: **Ridge regression**\n",
        "\n",
        "We use `cv=5` so the meta-learner is trained on out-of-fold predictions (more realistic and less leakage).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "rfdQ7JfBaHuS",
      "metadata": {
        "id": "rfdQ7JfBaHuS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27883891218669.57, tolerance: 163457864416.10596\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22296152462502.92, tolerance: 131523352296.64708\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23124810613449.484, tolerance: 132434725424.95358\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22364844937829.2, tolerance: 129343635688.60757\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20916845419790.875, tolerance: 131172568200.89124\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 83714.81505727435\n",
            "MSE: 23877719067.785275\n",
            "R^2: 0.9258811710616842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tdokkad/anaconda3-new/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22559402570652.938, tolerance: 129350475039.0364\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "# --- Stacking (DT + ElasticNet) ---\n",
        "\n",
        "prep = PREP_MODES[\"scale_all_after_ohe\"]\n",
        "\n",
        "# 1) Create `enet_best` as a Pipeline:\n",
        "enet_best = Pipeline([\n",
        "    ('prep', prep),\n",
        "    ('model', ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42, max_iter=10000))\n",
        "])\n",
        "\n",
        "# 2) Create `dt_best` as a Pipeline:\n",
        "dt_best = Pipeline([\n",
        "    ('prep', prep),\n",
        "    ('model', DecisionTreeRegressor(max_depth=None, min_samples_leaf=10, random_state=42))\n",
        "])\n",
        "\n",
        "# 3) Create `stack` as a StackingRegressor:\n",
        "stack = StackingRegressor(\n",
        "    estimators=[(\"dt\", dt_best), (\"enet\", enet_best)],\n",
        "    final_estimator=Ridge(alpha=0.9),\n",
        "    cv=5,\n",
        "    n_jobs=1)\n",
        "\n",
        "# 4) Fit on (X_train, y_train), then predict on test.\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "yhat_test = stack.predict(X_test)\n",
        "\n",
        "# 5) Print MAE, RSME, R^2, metrics for the X_test.\n",
        "print('MAE: ' + str(mean_absolute_error(y_test, yhat_test)))\n",
        "print('MSE: ' + str(mean_squared_error(y_test, yhat_test)))\n",
        "print('R^2: ' + str(r2_score(y_test, yhat_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
